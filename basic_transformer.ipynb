{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS0XHdhzzg8K",
        "outputId": "fe76b34b-dbef-4c04-caa5-c15e444bb9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63jXS0uCvU21",
        "outputId": "9d88ae65-d3a8-4fe7-9658-2deaab07e55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WRY0-ixv3fu",
        "outputId": "5a0895e3-d2a1-45b3-c082-55edb845243e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kiwipiepy\n",
            "  Downloading kiwipiepy-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting kiwipiepy-model<0.19,>=0.18 (from kiwipiepy)\n",
            "  Downloading kiwipiepy_model-0.18.0.tar.gz (34.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (4.66.5)\n",
            "Downloading kiwipiepy-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: kiwipiepy-model\n",
            "  Building wheel for kiwipiepy-model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kiwipiepy-model: filename=kiwipiepy_model-0.18.0-py3-none-any.whl size=34843380 sha256=b66d656332d6ee6bd70334645e12e51aa1982a2d966cddde96a879fc6f38b500\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/ea/f6/abb93f89cc196467624828ec9c29150c29a8399a589ba50bef\n",
            "Successfully built kiwipiepy-model\n",
            "Installing collected packages: kiwipiepy-model, kiwipiepy\n",
            "Successfully installed kiwipiepy-0.18.0 kiwipiepy-model-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install kiwipiepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYVd-qWIzZir",
        "outputId": "1c6c72c4-fc79-4c3d-df3c-4977473376cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Ign:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,134 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,449 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,173 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,553 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,423 kB]\n",
            "Fetched 9,999 kB in 4s (2,689 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmecab2 mecab-ipadic mecab-utils\n",
            "The following NEW packages will be installed:\n",
            "  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n",
            "0 upgraded, 6 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 7,367 kB of archives.\n",
            "After this operation, 59.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab2 amd64 0.996-14build9 [199 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab-dev amd64 0.996-14build9 [306 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-utils amd64 0.996-14build9 [4,850 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic all 2.7.0-20070801+main-3 [6,718 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mecab amd64 0.996-14build9 [136 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-3 [4,384 B]\n",
            "Fetched 7,367 kB in 3s (2,521 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmecab2_0.996-14build9_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-14build9) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../1-libmecab-dev_0.996-14build9_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-14build9) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../2-mecab-utils_0.996-14build9_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-14build9) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-3_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-3) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../4-mecab_0.996-14build9_amd64.deb ...\n",
            "Unpacking mecab (0.996-14build9) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-3_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n",
            "Setting up libmecab2:amd64 (0.996-14build9) ...\n",
            "Setting up libmecab-dev (0.996-14build9) ...\n",
            "Setting up mecab-utils (0.996-14build9) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-3) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-14build9) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Cloning into 'mecab-ko-dic'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "bash: mecab-ko-dic/tools/add-userdic.sh: No such file or directory\n",
            "cp: cannot stat 'mecab-ko-dic': No such file or directory\n",
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y mecab libmecab-dev mecab-ipadic-utf8\n",
        "!git clone --depth 1 https://github.com/gogumaUno/mecab-ko-dic.git\n",
        "!bash mecab-ko-dic/tools/add-userdic.sh\n",
        "!sudo cp -r mecab-ko-dic /usr/local/lib/mecab/dic/mecab-ko-dic\n",
        "!pip install mecab-python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPDLkJOY0vtm",
        "outputId": "9ccd4a54-32bc-4916-b92c-75a150e96e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lhg0UWek_XR",
        "outputId": "4e76eb72-4005-4fd3-a947-b7fe3860a381"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt, Kkma, Hannanum, Komoran\n",
        "from kiwipiepy import Kiwi\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "# DL 4팀에서 사용한 Feild 라이브러리는 torchtext 0.8.0 버전 부터 폐지되었기 때문에 pytorch 의 Dataset 과 DataLoader 를 사용\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# from torchtext.vocab import Vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj_NCqdHu7lz"
      },
      "outputs": [],
      "source": [
        "# conversations = pd.read_parquet(\"/content/drive/MyDrive/2024-2 KUBIG/Summer NLP/Contest/dataset/경상도_학습데이터_대화_통합_데이터.parquet\")\n",
        "# raw_data = pd.read_parquet(\"/content/drive/MyDrive/2024-2 KUBIG/Summer NLP/Contest/dataset/경상도_학습데이터_훈련_통합_데이터.parquet\")\n",
        "\n",
        "standard = pd.read_parquet(\"/content/drive/MyDrive/2024-2 KUBIG/Summer NLP/Contest/dataset/경상도_학습데이터_대화_표준버전.parquet\")\n",
        "dialect = pd.read_parquet(\"/content/drive/MyDrive/2024-2 KUBIG/Summer NLP/Contest/dataset/경상도_학습데이터_대화_방언버전.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXYOTLjel_1P"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame(columns=[\"id\", \"speaker_1\", \"speaker_2\"])\n",
        "data[\"id\"] = list(standard[\"id\"])\n",
        "data[\"speaker_1\"] = list(standard[\"speaker_1\"])\n",
        "data[\"speaker_2\"] = list(dialect[\"speaker_2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xtju0VWWwh2h"
      },
      "outputs": [],
      "source": [
        "# 구두점, 기호를 없애주고 소문자로 바꿔주는 함수\n",
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char  # space is also a character\n",
        "    return no_punct\n",
        "\n",
        "# 길이가 하나인 문자를 없애주는 함수\n",
        "def del_one_char(string):\n",
        "    result = []\n",
        "    string_seq = string.split(\" \")\n",
        "    for s in string_seq:\n",
        "        if len(s) != 1:\n",
        "            result.append(s)\n",
        "    return ' '.join(result)\n",
        "\n",
        "def is_len_over_three(string):\n",
        "    string_seq = string.split(\" \")\n",
        "    if len(string_seq) > 3:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgIS3pi7wn8i"
      },
      "outputs": [],
      "source": [
        "# 영어도 지울지는 잠시 보류\n",
        "data[\"speaker_1\"] = data[\"speaker_1\"].apply(lambda x : remove_punc(x))\n",
        "data[\"speaker_2\"] = data[\"speaker_2\"].apply(lambda x : remove_punc(x))\n",
        "\n",
        "# 이 가설이 정확할지는 모르겠으나, \"챗봇\" 구현에 중요한 요소 중 하나는 얼마나 사람처럼 응답하는가 인 것 같아\n",
        "# 한 글자짜리 단어를 모두 지울 시 어색해지지 않을까 하는 우려에서 우선 배제\n",
        "# data[\"speaker_1\"] = data[\"speaker_1\"].apply(lambda x : del_one_char(x))\n",
        "# data[\"speaker_2\"] = data[\"speaker_2\"].apply(lambda x : del_one_char(x))\n",
        "\n",
        "# 질의의 단어 수가 충분치 않은 경우, 질문과 응답의 영양가가 없어보여 느낌상 3개 초과의 단어로 구성된 문장만 반영하도록\n",
        "data = data[data[\"speaker_1\"].apply(lambda x : is_len_over_three(x))]\n",
        "data = data[data[\"speaker_2\"].apply(lambda x : is_len_over_three(x))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MZNRn1EfJCAo",
        "outputId": "8326d576-cdca-4572-cdc7-714b15a81986"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 94448,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7685,\n        \"samples\": [\n          \"DKSR20000212\",\n          \"DKSR20005321\",\n          \"DKSR20005151\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94338,\n        \"samples\": [\n          \" \\uc800\\ub294 \\uc800\\ub3c4 \\ubb50 \\uadf8\\ub807\\uac8c \\ud070 \\uacbd\\ud5d8\\uc740 \\uc544\\ub2cc\\ub370 \\uc81c\\uac00 \\uc5ec\\ub984 \\uc5ec\\ud589\\ubcf4\\ub2e4 \\uaca8\\uc6b8 \\uc5ec\\ud589\\uc744 \\ub354 \\uc88b\\uc544\\ud558\\ub294 \\uc774\\uc720 \\uc911\\uc5d0 \\ud558\\ub098\\ub3c4 \\uc81c\\uac00 \\uc0dd\\uac01\\ud558\\uae30\\uc5d0 \\ucea0\\ud551\\uc774 \\uaca8\\uc6b8\\uc774 \\ub354 \\uc88b\\ub2e4\\uace0 \\uc0dd\\uac01\\ud558\\uac70\\ub4e0\\uc694 \\ubb54\\uac00 \\ucd94\\uc6b8 \\ub54c \\ub530\\ub73b\\ud55c \\uc74c\\uc2dd\\uc744 \\ubc16\\uc5d0\\uc11c \\uba39\\ub294 \\uadf8\\ub7f0 \\uac8c \\ub354 \\uc88b\\ub354\\ub77c\\uad6c\\uc694 \\uc544\\ubb34\\ub798\\ub3c4 \\ubc8c\\ub808\\ub3c4 \\ub9ce\\uc774 \\uc5c6\\uace0 \\ubb3c\\ub860 \\uc7a0\\uc798 \\ub54c \\uc870\\uae08 \\ucda5\\uae34 \\ud55c\\ub370 \\uc774\\ub807\\uac8c \\uc0ac\\ub78c\\ub4e4\\uc774\\ub791 \\uac19\\uc774 \\uac00\\ub2e4 \\ubcf4\\uba74 \\uadf8\\ub7f0 \\uc628\\uae30\\ub3c4 \\ub290\\uaef4\\uc9c0\\uace0 \\ud558\\ub294 \\uac8c \\uc788\\uc5b4\\uac00\\uc9c0\\uace0 \\uc800\\ub294 \\uaca8\\uc6b8 \\uc5ec\\ud589\\uc774 \\ub354 \\uc88b\\ub2e4\\uace0 \\uc0dd\\uac01\\ud569 \\ud558\\uac70\\ub4e0\\uc694 \\uadf8\\uc911\\uc5d0\\uc11c\\ub3c4 \\ucea0\\ud551\\uc774 \\uc81c\\uc77c \\uc88b\\uc740 \\uac70 \\uac19\\uc740\\ub370 \\uc5f0\\ub9d0\\uc5d0 \\ucea0\\ud551\\uac14\\ub358 \\uacbd\\ud5d8\\uc774 \\uc870\\uae08 \\uc88b\\uc558\\ub358 \\uac70 \\uac19\\uc560\\uc694 \\uadf8\\uac70 \\ub9d0\\uace0\\ub294 \\ubb50 \\uadf8\\ub807\\uac8c \\ud070 \\uacbd\\ud5d8\\uc740 \\uc88b\\uc740 \\uacbd\\ud5d8\\uc740 \\uc5c6\\ub294 \\uac70 \\uac19\\uc740\\ub370 \\ud639\\uc2dc \\ucea0\\ud551 \\uac00 \\ubcf8 \\uc801 \\uc788\\uc73c\\uc138\\uc694\",\n          \"\\uc544\\ud508 \\ub370  \\uaca9\\ub9ac\\ub2f9\\ud55c\\ub2e4 \\ucf54\\ub85c\\ub098\\ub85c \\uc758\\uc2ec\\ub3fc\\uc11c\",\n          \"\\uadf8\\ub7fc \\uac70\\uae30 \\uc2f8\\uac04\\uac70\\ub9cc \\uba39\\uc5c8\\uc5b4\\uc694 \\uac70\\uae30 \\uc9c0\\ubc29\\uc5d0 \\uac00\\uc11c \\ubb58 \\uba39\\uc740\\uac8c \\uc544\\ub2c8\\uace0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94348,\n        \"samples\": [\n          \"\\uc5b4 \\uc6b0\\uc120 \\ubaa8\\ubc14\\uc77c \\uac8c\\uc784\\uc740 \\uc800\\ub294 \\uc2a4\\ub9c8\\ud2b8\\ud3f0\\uc73c\\ub85c \\ub118\\uc5b4\\uc624\\uae30 \\uc804\\uc5d0\\ub294 \\ub9ce\\uc774 \\ud588\\ub358 \\uac70 \\uac19\\uc544\\uc694 \\uc5b4 \\uc61b\\ub0a0\\uc5d0 \\uc800\\ud76c \\ud3f4\\ub354 \\ud3f0\\uc774\\ub098 \\uc2ac\\ub77c\\uc774\\ub4dc \\ud3f0 \\uc4f8 \\ub54c \\ub124\\uc774\\ud2b8 \\uc798\\ubabb \\ub204\\ub974\\uba74\\uc740 \\ub9c9 \\uc694\\uae08 \\ub098\\uc62c\\uae4c \\ubd10 \\uac81\\ub098\\ub358 \\uc2dc\\uc808\\uc5d0 \\ud3f0 \\uac8c\\uc784\\uc744 \\uc88b\\uc544\\ud588\\ub294\\ub370 \\uadf8\\ub54c \\uadf8 \\uc560\\ub2c8\\ucf5c \\uace0\\uc544\\ub77c\\ud3f0 \\uc774\\ub7f0 \\uac70 \\uc4f0\\uba74 \\uac15\\uc544\\uc9c0 \\ud0a4\\uc6b0\\uae30 \\uac8c\\uc784\\uc774 \\uc788\\uc5c8\\ub294\\ub370 \\uadf8\\uac70\\ub97c \\uc9c4\\uc9dc \\ub9ce\\uc774 \\ud588\\uc5c8\\uc5b4\\uc694 \\uadf8\\ub54c\\ub294 \\ubb50 \\ub2e4\\ub978 \\uc120\\ud0dd\\uc9c0\\uac00 \\uc5c6\\uc5b4\\uc11c \\uadf8\\uac78 \\ud55c \\uac83\\ub3c4 \\uc788\\uc5c8\\ub294\\ub370 \\uadf8\\uac70 \\ub9ce\\uc774 \\ud588\\uc5c8\\uace0 \\uadf8\\ub7ec\\ub2e4\\uac00 \\uc81c \\uae30\\uc5b5\\uc5d0 \\ud3f0 \\uac8c\\uc784\\uc73c\\ub85c \\uac00\\uc7a5 \\uc720\\uba85\\ud574\\uc9c4 \\uac8c \\ub9ac\\ub4ec\\uc2a4\\ud0c0\\ub77c\\uace0 \\uae30\\uc5b5\\ud558\\uac70\\ub4e0\\uc694 \\ub124 \\uadf8\\uac70 \\ub2e4\\uc6b4\\ubc1b\\uc544\\uc11c \\ub5a8\\uc5b4\\uc9c0\\ub294 \\ub178\\ud2b8\\uc5d0 \\ub9de\\ud600\\uc11c \\uc774\\ucf00 \\ubc84\\ud2bc\\uc744 \\ub9de\\ucd94\\ub294 \\ub9ac\\ub4ec \\uac8c\\uc784\\uc774\\uc5c8\\ub294\\ub370 \\uc81c\\uac00 \\uc624\\ud22c\\uc7bc\\uc774\\ub77c\\uace0 \\ub9ac\\ub4ec \\uac8c\\uc784\\uc774 \\uc788\\uc5b4\\uc694 \\ucef4\\ud4e8\\ud130\\ub85c \\ud558\\ub294 \\uadfc\\ub370 \\uc800\\ud76c \\uc0ac\\ucd0c \\ud615\\uc774 \\uadf8\\uac78 \\uc18c\\uac1c \\uc2dc\\ucf1c \\uc918\\uc11c \\uadf8\\uac78 \\ucef4\\ud4e8\\ud130\\ub85c\\ub9cc \\ud588\\uc5c8\\ub294\\ub370 \\uadf8\\ub54c\\ub294 \\uc800\\ud76c \\uc9d1\\uc5d0\\ub294 \\ucef4\\ud4e8\\ud130\\uac00 \\uc5c6\\uc5c8\\uace0 \\uadf8\\ub798\\uc11c \\uc624\\uc77c \\uc0ac\\ucd0c\\ud615 \\uc9d1\\uc5d0 \\uac14\\uc744 \\ub54c\\ub9cc \\ud560 \\uc218 \\uc788\\ub294 \\uac8c\\uc784\\uc774\\uc5c8\\ub294\\ub370 \\ub9ac\\ub4ec\\uc2a4\\ud0c0\\ub77c\\ub294 \\uac8c\\uc784\\uc774 \\ud3f0\\uc73c\\ub85c \\ub098\\uc624\\ub2c8\\uae50 \\uc5c4\\uccad \\ub9ce\\uc774 \\ud558\\uac8c \\ub410\\uace0 \\uadf8 \\ub9ac\\ub4ec\\uc2a4\\ud0c0 \\uac8c\\uc784\\uc5d0\\ub3c4 \\ub09c\\uc774\\ub3c4\\uac00 \\uc788\\ub358 \\uac78\\ub85c \\uae30\\uc5b5\\ud574\\uc694 \\ubb50 \\uc26c\\uc6c0 \\uc911\\uac04 \\ubb50 \\uc5b4\\ub824\\uc6c0 \\ubb50 \\uc774\\ub7f0 \\uc2dd\\uc73c\\ub85c \\ud574\\uc11c \\uadfc\\ub370 \\uadf8 \\uc5b4\\ub824\\uc6b4 \\uac70\\ub97c \\ud560\\ub824\\uba74 \\uadf8 \\uc5b4\\ub824\\uc6b4 \\uac70\\ub97c \\ub2e4\\uce60 \\uc218 \\uc788\\ub294 \\ud734\\ub300\\ud3f0\\uc774 \\uc81c \\uae30\\uc5b5\\uc73c\\ub860 \\ud55c\\uc815\\ub3fc \\uc788\\uc5c8\\uc5b4\\uc694 \\uadfc\\ub370 \\uadf8\\ub54c \\uc81c \\ud3f0 \\uae30\\uc885\\uc740 \\uadf8\\uac8c \\uc548 \\ub418\\ub294 \\uae30\\uc885\\uc774\\uc5c8\\uc5b4\\uc11c \\uadf8 \\ub9ac\\ub4ec\\uc2a4\\ud0c0\\ub97c \\uc798\\ud558\\uae30 \\uc704\\ud574\\uc11c \\ub3cc\\ud540\\ud3f0\\uc774\\ub77c\\uace0 \\uc57d\\uac04 \\ud718\\ub294 \\ud3f0\\uc774 \\uc788\\uc5c8\\ub294\\ub370 \\uadf8 \\ud3f0\\uc73c\\ub85c \\ud3f0\\uc744 \\ubc14\\uafc0 \\ub9cc\\ud07c \\ub9ac\\ub4ec\\uc2a4\\ud0c0\\ub77c\\ub294 \\uac8c\\uc784\\uc744 \\uc880 \\ub9ce\\uc774 \\ud588\\uc5c8\\uace0 \\uadf8 \\uc774\\ud6c4\\uc5d0 \\uc2a4\\ub9c8\\ud2b8\\ud3f0\\uc774 \\uc774\\uc81c \\ucc98\\uc74c \\ub098\\uc624\\uace0 \\uc575\\uadf8\\ub9ac\\ubc84\\ub4dc\\ub791 \\ucfe0\\ud0a4\\ub7f0 \\uadf8 \\uc815\\ub3c4\\uae4c\\uc9c0 \\ubaa8\\ubc14\\uc77c \\uac8c\\uc784\\uc744 \\ub9ce\\uc774 \\ud588\\uace0 \\uadf8 \\uc774\\ud6c4\\uc5d0 \\ub098\\uc624\\ub294 \\ud3f0 \\uac8c\\uc784\\ub4e4\\uc740 \\uc0ac\\uc2e4 \\ud765\\ubbf8\\uac00 \\uc880 \\ub5a8\\uc5b4\\uc838\\uc11c \\uc548 \\ud558\\uac8c \\ub410\\uc5b4\\uc694 \\uadf8 \\uc774\\uc720\\uac00 \\uc81c\\uac00 \\uc720\\ud29c\\ube0c\\ub098 \\uc774\\ub7f0 \\uc601\\uc0c1\\uc744 \\ub9ce\\uc774 \\ubcf4\\ub294 \\ud3b8\\uc778\\ub370 \\uadf8 \\uc601\\uc0c1\\uc744 \\ubcf4\\uace0 \\uac8c\\uc784\\uae4c\\uc9c0 \\ud558\\uc790\\ub2c8 \\ub208\\uc5d0 \\ud53c\\ub85c\\uac10\\uc774 \\ub108\\ubb34 \\uc2ec\\ud558\\uace0 \\ud734\\ub300\\ud3f0 \\ubc30\\ud130\\ub9ac\\ub3c4 \\uac10\\ub2f9\\uc774 \\uc548 \\ub3fc\\uc11c \\uc548 \\ud558\\uac8c \\ub410\\uace0 \\uc624\\ud788\\ub824 \\ubaa8\\ubc14\\uc77c \\uac8c\\uc784\\uc5d0\\uc11c \\uc990\\uae30\\ub294 \\uac70\\ub294 \\uc57d\\uac04 \\ud0ac\\ub9c1\\ud0c0\\uc784\\uc6a9 \\uac8c\\uc784\\uc744 \\ub9ce\\uc774 \\ud558\\uac8c \\ub418\\ub294\\ub370 \\uadf8\\uc911\\uc5d0 \\uc5b4 \\uc800\\ub294 \\ud14c\\ud2b8\\ub9ac\\uc2a4 \\ube44\\uc2b7\\ud55c \\uac74\\ub370 \\uc774\\uac8c \\uc5b4 \\uc5b4\\ub5bb\\uac8c \\uc124\\uba85\\uc744 \\ub4dc\\ub824\\uc57c \\ub418\\uc9c0 \\ud37c\\uc990 \\ub9de\\ucd94\\uae30 \\uac8c\\uc784\\ud558\\uace0 \\ud14c\\ud2b8\\ub9ac\\uc2a4\\uac00 \\ud569\\uccd0\\uc9c4 \\uadf8\\ub7f0 \\uac8c\\uc784\\uc774\\ub77c\\uace0 \\ubcf4\\uba74 \\ub418\\ub294\\ub370 \\ud55c \\ubc88 \\uac8c\\uc784 \\ucc3d\\uc774 \\ub728\\uba74\\uc740 \\ud14c\\ud2b8\\ub9ac\\uc2a4 \\ub9d0 \\uc911\\uc5d0 \\uc138 \\uac00\\uc9c0 \\ud615\\ud0dc\\uac00 \\ub098\\uc624\\uac70\\ub4e0\\uc694 \\uadf8\\ub2e4\\uc74c\\uc5d0 \\ub610 \\uc138 \\uac00\\uc9c0\\uac00 \\ubb50\\uac00 \\uc124\\uc815\\uc774 \\ub420\\uc9c0 \\ubab0\\ub77c\\uc11c \\uc774\\ub807\\uac8c \\uc138 \\uac00\\uc9c0\\ub97c \\uc804\\ub7b5\\uc801\\uc73c\\ub85c \\uc798 \\ucc44\\uc6b0\\ub294 \\uadf8\\ub798\\uc11c \\uadf8\\ub2e4\\uc74c \\ud398\\uc774\\uc9c0\\uc5d0 \\uc138 \\uac1c\\uac00 \\ub098\\uc654\\ub294\\ub370 \\ub354 \\uc774\\uc0c1 \\ub193\\uc744 \\uacf5\\uac04\\uc774 \\uc5c6\\uc73c\\uba74\\uc740 \\uc8fd\\uac8c \\ub418\\ub294 \\uac8c\\uc784\\uc778\\ub370 \\ub124 \\uadf8\\ub7f0 \\ud0ac\\ub9c1\\ud0c0\\uc784\\uc6a9 \\uac8c\\uc784\\uc744 \\ubb50 \\ubc84\\uc2a4 \\uae30\\ub2e4\\ub9ac\\uba74\\uc11c\\ub098 \\uc9e7\\uac8c \\uc774\\ub3d9\\ud560 \\ub54c \\ud558\\ub294 \\ud3b8\\uc774\\uace0 \\ub2e4\\ub978 \\ubaa8\\ubc14\\uc77c \\uac8c\\uc784\\uc740 \\uc548 \\ud558\\ub294 \\uac70 \\uac19\\uc544\\uc694 \\uadf8\\ub9ac\\uace0 \\ubcf4\\ub4dc\\uac8c\\uc784\\uc740 \\ucc98\\uc74c\\uc5d0 \\ub8e8\\ubbf8\\ud050\\ube0c\\ub97c \\uc815\\ub9d0 \\ub9ce\\uc774 \\ud588\\uc5c8\\uace0 \\ubc45\\uc774\\ub77c\\ub294 \\uac8c\\uc784\\uc774 \\uc788\\uc5b4\\uc694 \\ubc45\\uc774\\ub780 \\uac8c\\uc784\\uc774 \\uc774\\uc81c \\uc6d0\\uce74\\ub4dc \\ube44\\uc2b7\\ud55c \\uac8c\\uc784\\uc778\\ub370 \\uc644\\uc804 \\uac8c\\uc784 \\ud615\\uc2dd\\uc774 \\ub2e4\\ub974\\uae34 \\ud55c\\ub370 \\uad73\\uc774 \\uc124\\uba85\\ud558\\uc790\\uba74 \\uc6d0\\uce74\\ub4dc \\uac19\\uc740 \\uac74\\ub370 \\uacf5\\uaca9\\ud558\\ub294 \\uce74\\ub4dc\\uac00 \\uc788\\uace0 \\ubb50 \\ubc29\\uc5b4\\ud558\\ub294 \\uce74\\ub4dc\\uac00 \\uc788\\uace0 \\uadf8\\ub807\\uac8c \\ud574\\uc11c \\uc11c\\ub85c\\uc11c\\ub85c \\uacf5\\uaca9\\ud558\\uace0 \\ubc29\\uc5b4\\ud558\\uba74\\uc11c \\ubaa9\\uc228\\uc774 \\ub2e4 \\ub2f3\\uc73c\\uba74 \\uc8fd\\ub294 \\uac8c \\uadf8\\uac8c \\uc800\\ud76c \\uc0ac\\ucd0c \\ud615\\uc774 \\ucc98\\uc74c \\uc18c\\uac1c \\uc2dc\\ucf1c \\uc92c\\ub294\\ub370 \\uc0ac\\ucd0c \\ud615\\uc774 \\ubcf4\\ub4dc\\uac8c\\uc784\\uc744 \\uc815\\ub9d0 \\uc88b\\uc544\\ud558\\ub294\\ub370 \\uc81c\\uac00 \\ub2e4\\ub978 \\ubcf4\\ub4dc\\uac8c\\uc784\\uc740 \\uc798 \\uc548 \\ub9de\\uc544\\uc11c \\uc548 \\ud558\\ub294\\ub370 \\uadf8 \\ubc45\\uc774\\ub77c\\ub294 \\uac8c\\uc784\\uc740 \\uc800\\ud55c\\ud14c \\uc815\\ub9d0 \\uc798 \\ub9de\\uc544\\uc11c \\uc880 \\uc624\\ub798 \\ud588\\ub358 \\uae30\\uc5b5\\uc774 \\uc788\\uace0 \\uadf8\\ub798\\uc11c \\uc81c\\uac00 \\uadf8 \\ubc45\\uc744 \\uad70\\ub300\\uc5d0 \\ub4e4\\uace0 \\uac00\\uc11c \\uad70\\ub300\\uc5d0\\uc11c \\ud560 \\ub9cc\\ud07c \\ucacc \\uc88b\\uc544\\ud588\\ub358 \\ubcf4\\ub4dc\\uac8c\\uc784\\uc774\\uc5d0\\uc694 \\ud639\\uc2dc \\ubcf4\\ub4dc\\uac8c\\uc784 \\uc911\\uc5d0\\uc11c \\uc880 \\uc7ac\\ubc0c\\uac8c \\ud558\\uc168\\uac70\\ub098 \\uc18c\\uac1c\\ud574 \\uc8fc\\uc2e4 \\ub9cc\\ud55c \\uac83\\uc774 \\uc788\\ub098\\uc694\",\n          \"\\uadfc\\ub370 \\uc774\\uc81c \\uac71\\uc815\\uc778 \\uac8c \\uadf8 \\uc81c\\uac00 \\ucc28\\ub97c \\uc774\\uc81c \\uae30\\ub2a5\\uc5d0 \\ucc98\\uc74c  \\uae30\\ub2a5\\uc5d0\\uc11c\\ub294 \\uc774\\uc2ed\\ud0a4\\ub85c \\ubbf8\\ub9cc\\uc73c\\ub85c \\ud558\\uc796\\uc544\\uc694 \\uadfc\\ub370 \\ubc16\\uc5d0 \\ub098\\uac00\\uba74 \\uc774\\uc2ed \\ud0a4\\ub85c  \\ud070\\uc77c \\ub098\\uc796\\uc544\\uc694\",\n          \"\\ub9de\\uc544 \\uadf8\\ub798\\uc11c \\uc0ac\\ub78c\\ub4e4\\uc774 \\uc5b4 \\uc9c0\\ube0c\\ub9ac \\uc2a4\\ud29c\\ub514\\uc624\\uc5d0 \\uadf8 \\ube44\\uc9c0\\uc5e0\\ub4e4\\uc744 \\ub530\\ub85c \\ubaa8\\uc544\\uc11c \\ub4e3\\uae30\\ub3c4 \\ud558\\ub294\\ub370 \\uadf8\\ub807\\uac8c \\ub4e3\\ub294 \\uc774\\uc720\\uac00 \\uadf8\\ub0e5 \\ub9c8\\ub0e5 \\uadf8 \\ub178\\ub798\\uac00 \\uc88b\\uc544\\uc11c \\ubfd0\\ub9cc\\uc774 \\uc544\\ub2c8\\ub77c \\ubb54\\uac00 \\uadf8 \\uadf8 \\uc74c\\uc545\\uc744 \\ub4e4\\uc73c\\uba74 \\uc61b\\ub0a0\\uc5d0 \\uc5b4\\ub9b0 \\uc2dc\\uc808\\uc5d0 \\ud5a5\\uc218\\uac00 \\ub610 \\ub5a0\\uc624\\ub974\\ub2e4 \\ubcf4\\ub2c8\\uae4c \\uadf8 \\ub178\\ub798\\ub4e4\\uc744 \\ub9ce\\uc774 \\ucc3e\\uc544 \\ub4e3\\ub294 \\uac83\\ub3c4 \\ubd24\\uc5c8\\uc5b4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e5a6f8e7-9f1b-433f-aa75-a952ce7dc032\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>speaker_1</th>\n",
              "      <th>speaker_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DKCI20000001</td>\n",
              "      <td>자 음식을 멀 좋아하느냐 하면은 나는 사실은 다 좋아합니다 다 좋아하는데 특히 육류...</td>\n",
              "      <td>아 자기 아 오리를 싫어했었구나</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DKCI20000001</td>\n",
              "      <td>머 못 먹 그리고 모든걸 다 좋아하는 데 즐기진 않는다</td>\n",
              "      <td>즐기진 않는다 자기는 나하고 반대네 나는 야채를 좋아하거든</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DKCI20000001</td>\n",
              "      <td>머라노 그 곁들어 먹는</td>\n",
              "      <td>곁들어먹는거 근데 야채를 많이 먹어야 건강해요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DKCI20000001</td>\n",
              "      <td>그래서 음식에 가린다는 것은 나는 한편으로 불행하다 생각합니다 아니 어쩔수 없이 먹...</td>\n",
              "      <td>그러면 사실은 우리는 뭐 없어서 못 묵지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DKCI20000001</td>\n",
              "      <td>밥을 챙겨먹는 생각도 의미 없다고 생각해 영양분이 되고 배가 부르면은 한 끼 식사로...</td>\n",
              "      <td>근데 나는 그기서 쪼끔 반대하는기 머냐면 이 인제 밥이 탄수화물이잖아 탄수화물인데 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5a6f8e7-9f1b-433f-aa75-a952ce7dc032')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5a6f8e7-9f1b-433f-aa75-a952ce7dc032 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5a6f8e7-9f1b-433f-aa75-a952ce7dc032');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2b0cd96-d836-4203-a2d1-3b91960c6a02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2b0cd96-d836-4203-a2d1-3b91960c6a02')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2b0cd96-d836-4203-a2d1-3b91960c6a02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             id                                          speaker_1  \\\n",
              "0  DKCI20000001  자 음식을 멀 좋아하느냐 하면은 나는 사실은 다 좋아합니다 다 좋아하는데 특히 육류...   \n",
              "1  DKCI20000001                     머 못 먹 그리고 모든걸 다 좋아하는 데 즐기진 않는다   \n",
              "3  DKCI20000001                                       머라노 그 곁들어 먹는   \n",
              "5  DKCI20000001  그래서 음식에 가린다는 것은 나는 한편으로 불행하다 생각합니다 아니 어쩔수 없이 먹...   \n",
              "7  DKCI20000001  밥을 챙겨먹는 생각도 의미 없다고 생각해 영양분이 되고 배가 부르면은 한 끼 식사로...   \n",
              "\n",
              "                                           speaker_2  \n",
              "0                                  아 자기 아 오리를 싫어했었구나  \n",
              "1                   즐기진 않는다 자기는 나하고 반대네 나는 야채를 좋아하거든  \n",
              "3                          곁들어먹는거 근데 야채를 많이 먹어야 건강해요  \n",
              "5                             그러면 사실은 우리는 뭐 없어서 못 묵지  \n",
              "7  근데 나는 그기서 쪼끔 반대하는기 머냐면 이 인제 밥이 탄수화물이잖아 탄수화물인데 ...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WUzahA0yLat9",
        "outputId": "d37bbe03-a074-4afe-f89a-044169e273cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DKSR20007343\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ubcc4\\ub85c \\uc800\\ub294 \\uadf8\\uac70 \\ub178\\ub798 \\uadf8\\ub807\\uac8c \\ub9c9 \\uc798\\ud558 \\uc544 \\uc798\\ud558\\ub294 \\uac74 \\uc54c\\uaca0\\ub294\\ub370 \\uadfc\\ub370 \\ub9c9 \\uacc4\\uc18d \\ubcf4\\uace0 \\uc2f6\\uace0 \\ubd24\\ub358 \\uac78 \\ub610 \\ubcf4\\uace0 \\ub610 \\ubcf4\\uace0 \\ud560 \\ub9cc\\ud07c\\uc758 \\uadf8 \\uc815\\ub3c4\\ub294 \\uc544\\ub2c8\\ub77c\\uace0 \\uc0dd\\uac01\\ud558\\uac70\\ub4e0\\uc694 \\uc5c4\\ub9c8 \\uc544 \\uadf8\\ub798\\uc11c \\uc5c4\\ub9c8 \\ubd24\\ub294\\ub370 \\uc65c \\ub610 \\ubcf4\\ub0d0\\uace0 \\ub2e4\\ub978 \\uc7ac\\ubbf8\\uc788\\ub294 \\ud504\\ub85c\\uadf8\\ub7a8 \\ubcf4\\uc790\\ub77c\\uace0 \\uba87 \\ub9c8\\ub514 \\ud588\\ub294\\ub370 \\uadf8\\uac74 \\uad6c\\ubc15\\uc740 \\uc544\\ub2c8\\uc9c0 \\uad6c\\ubc15\\uc740 \\uadf8\\uac74 \\uc790 \\uc544\\ub2cc\\ub370 \\uc5b4\\uca0c\\ub4e0 \\uc5c4\\ub9c8\\uac00 \\ud558\\uc5ec\\ud2bc \\uadf8\\ub798\\ub3c4 \\uadf8\\uac78 \\ubcf4\\uba74\\uc11c \\ub9c9 \\uc88b\\uc544\\ud558\\ub294 \\uac8c \\uc788\\uace0 \\ub9c9 \\ucf58\\uc11c\\ud2b8 \\ubcf4\\ub7ec \\uac00\\uc790 \\uadf8\\ub7ec\\uace0 \\uadf8\\uac8c \\ub09c \\uc9c4\\uc9dc \\uc88b\\uc558\\uac70\\ub4e0 \\uadfc\\ub370 \\uc774\\uc81c \\ucf58\\uc11c\\ud2b8\\ub3c4 \\ucf54\\ub85c\\ub098\\ub9cc \\uc544\\ub2c8\\uc5c8\\uc73c\\uba74 \\uc548\\ub3d9 \\ud45c\\ub97c \\uc9c4\\uc9dc \\uc5b4\\ub835\\uac8c \\uc608\\ub9e4\\ub97c \\ud588\\ub294\\ub370 \\ucc38 \\ubcf4\\ub7ec\\uac14\\uc5c8\\uc73c\\uba74 \\ucc38 \\uc88b\\uc558\\uc744 \\ud150\\ub370 \\uadf8 \\ucf54\\ub85c\\ub098\\uac00 \\ubc88\\uc838 \\uac00\\uc9c0\\uace0 \\uc804\\uccb4 \\uadf8\\ub0e5 \\uacf5\\uc5f0\\uc744 \\ucde8\\uc18c\\ud558\\uac8c \\ub3fc \\uac00\\uc9c0\\uace0 \\uc5c4\\ub9c8\\uac00 \\uc2e4\\ubb3c\\ub85c \\uc784\\uc601\\uc6c5\\uc744 \\ubabb \\ubd10\\uc11c \\uc548 \\ud55c \\uac70\\uc9c0 \\ub108\\ubb34 \\uc544\\uc27d\\ub2e4 \\uadf8 \\uc9c4\\uc9dc \\uadf8 \\uc608\\ub9e4\\ud558\\ub824\\uad6c \\ub9c9 \\ub300\\uae30 \\ud0c0\\uace0 \\uc5c4\\uccad \\ud574 \\uac00\\uc9c0\\uace0 \\uc5b4\\ub835\\uac8c \\uadf8 \\ud45c\\ub97c \\uad6c\\ub9e4\\ud55c \\uac70\\uc600\\uc5c8\\ub294\\ub370 \\ub300\\uad6c\\ub294 \\ub610 \\uacf5\\uc5f0\\uc744 \\ud588\\uc73c\\uba74\\uc11c \\uc11c\\uc6b8\\uc774\\ub791 \\ud588\\uc73c\\uba74\\uc11c \\uc548\\ub3d9\\uc740 \\ucde8\\uc18c\\ud55c \\uac8c \\uc544 \\ub108\\ubb34 \\ucabc\\ub054 \\uc544\\uc27d\\ub354\\ub77c\\uad6c \\uadf8 \\ub2e4\\uc74c\\uc5d0 \\uae30\\ud68c\\uac00 \\ub418\\uba74 \\uadf8 \\uc784\\uc601\\uc6c5 \\ub178\\ub798 \\ubd80\\ub974\\ub294 \\ub370 \\ud55c\\ubc88 \\ubb50 \\ucf58\\uc11c\\ud2b8\\ub4e0 \\uc544\\ub2c8\\uba74 \\uadf8\\ub0e5 \\uacf5\\uc5f0\\uc7a5\\uc774\\ub4e0 \\ud558\\uc5ec\\ud2bc \\uac00\\uc11c \\ubcf4\\uba74 \\uc88b\\uaca0\\ub2e4\\ub77c\\uace0 \\uc0dd\\uac01\\uc774 \\ub4e4\\uc5c8\\uace0 \\uadfc\\ub370 \\uc784\\uc601\\uc6c5\\ub3c4 \\uc88b\\uc544\\ud558\\uc9c0\\ub9cc \\uc774\\ucc2c\\uc6d0\\ub3c4 \\uc88b\\uc544\\ud558\\uc9c0\\ub9cc \\uc5c4\\ub9c8 \\ub610 \\uae40\\ud638\\uc911\\ub3c4 \\uc88b\\uc544\\ud558\\uc796\\uc544 \\uadf8 \\uc0ac\\ub78c\\ub3c4 \\uc9c4\\uc9dc \\ub178\\ub798 \\uc798 \\ubd80\\ub978\\ub2e4 \\uadf8\\ub7ec\\uba74\\uc11c \\uc5c4\\ub9c8\\uac00 \\uc5c4\\uccad \\uce6d\\ucc2c\\ud588\\uc5c8\\uc796\\uc544 \\uc784 \\uae08 \\uae40\\ud638\\uc911\\uc740 \\uc5b4\\ub5bb\\uac8c \\uc0dd\\uac01\\ud574\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ub0b4\\uac00 \\uadf8 \\ub2f9\\uc2dc\\uc5d0\\ub294 \\uc784\\uc601\\uc6c5 \\uc601\\uc6c5\\uc774\\ud55c\\ud14c \\ube60\\uc838 \\uac16\\uace0 \\ub2e4\\ub978 \\uc0ac\\ub78c\\uc774 \\uc548 \\ubcf4\\uc5ec \\uac00\\uc8fc\\uace0 \\ubab0\\ub790\\ub294\\ub370 \\ub0b4\\uac00 \\uadf8 \\uc800\\uae30 \\ucc2c\\uc6d0\\uc774\\uace0 \\ud638\\uc911\\uc774\\uace0 \\uadf8 \\uc0ac\\ub78c\\ub4e4 \\ub178\\ub798\\ud558\\ub294 \\uae30 \\uace0 \\ub2f9\\uc2dc\\ub9cc \\ub0b4\\uac00 \\ub4e4\\uc5c8\\uc744 \\ubfd0\\uc774\\uc9c0 \\ub0b4 \\uc7a0 \\uba38\\ub9ac\\uc5d0 \\uc774\\ub974\\ucf00 \\ub0a8\\uc544 \\uc794\\uc0c1\\uc774 \\uc548 \\ub0a8\\uc544\\uac00 \\uc788\\uc5b4 \\uc601\\uc6c5\\uc774 \\ubfd0\\uc774\\ub77c \\uadf8\\ub798 \\uadf8\\ub54c\\ub294 \\uc644\\uc804 \\uc601\\uc6c5\\uc774\\ud55c\\ud14c \\uc774\\ub798 \\ubbf8\\uccd0 \\uac16\\uace0 \\ubab0\\ub790\\ub294\\ub370 \\ub05d\\ub098\\uace0 \\uacbd\\uc5f0\\uc774 \\ub05d\\ub098\\uace0 \\uc774\\ub798 \\ubcf4\\ub2c8\\uae4c \\uc544 \\ud638\\uc911\\uc774\\ub3c4 \\ub178\\ub798\\ub97c \\uadf8\\ub7f0\\ub370 \\uc778\\uc81c \\ud638\\uc911\\uc774\\ub294 \\ub098\\ub294 \\uc2eb\\uc5b4 \\uadf8 \\ub178\\ub798\\ub294 \\uc88b\\uc740 \\uc88b\\uc740\\ub370 \\uc5b4 \\ud638\\uc911\\uc774 \\uc0ac\\ub78c\\uc774 \\uc2eb\\uc5b4\\uac00 \\uadf8\\ub7f0\\uac00 \\ud638\\uc911\\uc774 \\ub178\\ub798\\ub3c4 \\uc778\\uc790 \\uc800\\uadf8 \\ucc98\\uc74c\\uc5d0\\ub294 \\uc544 \\ub178\\ub798\\ub97c \\uc798\\ud55c\\ub2e4\\uce74\\uba74\\uc11c \\uc774\\ub798 \\uc774\\ub798 \\ub4e4\\uc5c8\\ub294\\ub370 \\uc11c\\uc11c\\ud788 \\uadf8 \\uc0ac\\ub78c\\uc740 \\uc78a\\ud600\\uc838 \\uac00\\ubfcc\\ub9ac \\uadf8\\ub807\\uace0 \\uadf8 \\uc778\\uc81c \\uc601\\uc6c5\\uc774 \\ub300\\uc2e0 \\ub098\\ub294 \\ucc2c\\uc6d0\\uc774\\uac00 \\ub108\\ubb34\\ub108\\ubb34 \\ub610 \\uc88b\\uc740\\uae30\\ub77c \\uc694\\uc998\\uc740 \\uadfc\\ub370 \\uc778\\uc790 \\uc774 \\uc9c0\\ub098\\uace0 \\ubcf4\\ub2c8\\uae4c \\uc544 \\uc774\\uac8c \\ud504\\ub85c \\uacbd\\uc5f0\\uc5d0\\uc11c \\uadf8 \\uc77c\\uc774\\uc0bc \\ub4f1 \\ud588\\ub294 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uc774\\ub798 \\ubcf4\\ub2c8\\uae4c \\uc6b0\\ub9ac\\uac00 \\ubab0\\ub77c\\uc11c \\uadf8\\ub807\\uc9c0 \\uadf8 \\uc0ac\\ub78c\\ub4e4\\uc740 \\ucc2c\\uc6d0\\uc774 \\ube7c\\uace0 \\ub098\\uba38\\uc9c0\\ub294 \\uc804\\ubd80 \\ub2e4 \\uc5b4 \\uc9c0\\uae08\\uae4c\\uc9c0 \\ud55c \\uc2ed \\ubb50 \\uc2ed \\uc2ed\\uc218 \\ub144 \\ud588\\ub294 \\uc0ac\\ub78c\\ub3c4 \\uc788\\uace0 \\ub610 \\ubb50 \\uc9e7\\uc740 \\uc0ac\\ub78c\\uc740 \\ubb50 \\uc5b4 \\uc2ed \\ub144 \\ubbf8\\ub9cc\\uc778 \\uc0ac\\ub78c\\ub3c4 \\uc788\\ub294\\ub370 \\ub098\\uba38 \\ubb50 \\ub098 \\uadf8 \\uc800\\uae30 \\uac00\\uc218 \\ud65c\\ub3d9\\uc744 \\ud558\\uace0 \\uc788\\uc5c8\\ub358 \\uc0ac\\ub78c\\ub4e4\\uc774\\ub77c \\uc6b0\\ub9ac\\uac00 \\ubab0\\ub77c\\uc11c \\uadf8\\ub807\\uc9c0 \\uc5b4 \\uadf8 \\ubb50 \\uadf8\\ub978 \\uac00\\uc694\\ub97c \\uc548 \\ubcf4\\uace0 \\uc774\\ub974\\ucf00 \\uc548 \\ud558\\ub2c8\\uae4c \\ubab0\\ub77c\\uac00 \\uadf8\\ub7f0\\ub370 \\uadf8\\ub798 \\uac00\\ub9cc \\ubcf4\\ub2c8\\uae4c \\uc9c0\\uae08\\uc740 \\uc774\\ub798 \\uc74c \\uc598\\ub4e4\\uc744 \\uc774\\ub798 \\ubcf4\\uba74\\uc740 \\ub0b4\\uac00 \\ucabc\\uaf3c \\ub108\\ubb34 \\uc774\\ub974\\ucf00 \\ubb50 \\uc774\\ub7f0 \\ubb34\\uc9c0\\ud55c\\ub2e4 \\ubb34\\uc9c0\\ud558\\ub2e4\\uce74\\uc774 \\uc774\\uce90\\uc57c \\ub418\\uaca0\\ub098 \\uc54c\\uace0 \\ubcf4\\uba74\\uc740 \\ubed4\\ud55c \\uac74\\ub370 \\uc5ec \\ud55c \\ud55c\\ub3d9\\uc548\\uc5d0 \\ub0b4\\uac00 \\ub108\\ubb34 \\ubbf8\\uccd0 \\uac00\\uc8fc\\uace0 \\uadf8 \\ubaa9\\uc694\\uc77c\\ub0a0 \\ud558\\uba74\\uc740 \\uc774\\uac83 \\uc5d0\\uc774\\ud3ec \\uc6a9\\uc9c0\\uc5d0 \\uc774\\ub984\\uae4c\\uc9c0 \\uc801\\uc5b4\\uac00\\uba70 \\uc57c\\ub4e4\\uc774 \\uba87 \\uc810 \\ubc1b\\uc558\\ub2e4\\uce74\\ub294 \\uac70 \\ub9c9 \\uc801\\uc5b4 \\uac00\\uba74\\uc11c \\ub0b4\\ub3c4\\ub85d \\uacf5\\ubd80\\ub97c \\ub9c9 \\ud588\\uc5b4 \\uadf8 \\uc9c0\\ub098\\uace0 \\ub098\\ub2c8\\uae4c \\uc694\\uc998 \\uc598\\ub4e4\\uc774 \\ub098\\uc624\\ub294 \\uc774 \\ud504\\ub85c\\ub97c \\ud0c1 \\ubcf4\\ub2c8\\uae4c \\ub0b4\\uac00 \\ubbf8\\ucce4\\ub2e4\\uce74\\uba74\\uc11c \\uc774\\ub7f0 \\uc0dd\\uac01\\uc774 \\ub9c9 \\ub4dc\\ub294 \\uac8c \\uadf8 \\uc7a5\\ubbfc\\ud638\\ub2e4\\ub77c\\ub4e0\\uac00 \\uc601\\ud0c1\\uc774\\ub77c\\ub4e0\\uac00 \\uc774\\ub798 \\uc774\\ub798 \\uadf8 \\uac19\\uc774 \\uc5b4\\uc6b8\\ub9ac\\ub294 \\uc774\\ub798 \\uac00\\uc218\\ub4e4\\uc744 \\ubcf4\\ub2c8\\uae4c \\uadf8 \\ub098\\ubb3c\\uc5d0 \\uadf8 \\ubc25\\uc774\\ub77c \\uadf8\\ub798 \\uadf8\\uac70\\ub97c \\ub0b4\\uac00 \\uadf8\\ub54c\\ub294 \\ubab0\\ub790\\uc5b4 \\ub0b4 \\uc57c \\uc57c\\ub4e4\\uc774 \\uc2e0\\uc120\\ud55c \\uc904 \\uc54c\\uc558\\ub2e4\\ub2c8\\uae4c \\uc5b4 \\ucc98\\uc74c \\ub0b4\\uac00 \\ucc98\\uc74c \\ubd24\\uc73c\\ub2c8\\uae4c \\uadf8\\ub798 \\uc54c\\uace0 \\ubcf4\\ub2c8\\uae4c \\uac00\\uc218 \\ud65c\\ub3d9\\uc744 \\uae30\\uc874\\uc5d0 \\ud558\\uace0 \\uc774\\ub974\\ucf00 \\uc774\\ub7ec \\uadf8\\ub9ac \\uc9c0\\uae08 \\ub0b4 \\ub208\\uc5d0\\ub294 \\ub178\\ub798\\ub294 \\ub178\\ub798\\uace0 \\uc0ac\\ub78c\\uc73c\\ub85c \\uc778\\uc81c \\uc774\\ub798 \\ubcf4\\uc774\\ub294 \\uac70\\ub77c \\uadf8 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uc5b4 \\uac00\\uc218\\ub77c\\uce74\\ub294 \\uadf8 \\uadf8 \\uce58 \\uadf8 \\uc9c0 \\uc9c0 \\uc9c1\\uc5c5\\uc758 \\uad70\\uc73c\\ub85c \\uadf8\\uc2a4 \\uc0ac\\ub78c\\ub9cc \\ub531 \\ubcf4\\uc774\\ub294 \\uae30\\ub77c \\ub178\\ub798\\ub294 \\ucacc \\ub4b7\\uc804\\uc774\\uace0 \\uadf8\\ub798\\uc11c \\ucabc\\uae08 \\ud658\\uba74\\uc744 \\ub290\\uaf08\\ub2e4 \\uce90\\uc57c \\ub418\\uaca0\\ub098 \\uc5b4 \\ucabc\\uaf3c \\uc774\\ub974\\ucf00 \\ub108\\ubb34 \\uc774\\ub974\\ucf00 \\ub0b4\\uac00 \\ucc98\\uc74c\\uc5d0 \\ubd24\\ub358 \\uadf8\\ub978 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uc544\\ub2c8\\ub77c \\uadf8\\ub798\\uc11c \\uc2eb\\uc5b4 \\uadf8\\ub798\\uac00 \\uc694\\uc988\\uc74c\\uc5d0\\ub294 \\uadf8 \\uc0ac\\ub78c\\ub4e4\\uc740 \\uc778\\uc81c \\uc548 \\ubd10 \\uadf8 \\uc0ac\\ub78c\\ub4e4\\uc740 \\ub0b4\\uac00 \\uba40\\uc5b4\\uc84c\\uace0 \\ub2e4\\ub978 \\ud504\\ub85c\\uc5d0\\uc11c \\uc774\\ub974\\ucf00 \\uc774\\ub798 \\ubcf4\\ub2c8\\uae4c \\ub610 \\uc774\\ub974\\ucf00 \\ubb50 \\uc77c\\uc5b5\\uc744 \\ud0c0\\ub294 \\uc774\\ub798 \\uc0ac\\ub78c\\uc774 \\uc788\\uc5b4 \\uadf8 \\uc5bc\\ub9c8 \\uc804\\uc5d0 \\uc885 \\ub05d\\ub0ac\\ub294\\ub370 \\uadf8\\ub798 \\uc544 \\uc774 \\uc0ac\\ub78c\\ub3c4 \\ub610 \\uc54c\\uace0 \\ubcf4\\ub2c8\\uae4c \\uc2ed \\ub144\\uc774 \\ub118\\uc5c8\\ub4dc\\ub77c\\uace0 \\uac00\\uc218 \\ud65c\\ub3d9 \\ud588\\ub294 \\uc9c0\\uac00 \\uc6b0\\ub9ac\\ub9cc \\uc6b0\\ub9ac\\uac00 \\ubab0\\ub77c\\uc11c \\uadf8\\ub7ac\\ub294\\ub370 \\uadf8\\uac8c \\uc778\\uc790 \\uac00\\uc218\\ub77c\\uce74\\ub294 \\uac8c \\ubb50 \\uc6b0\\ub9ac \\ub9e8\\ub0a0 \\ud14c\\ub808\\ube44\\uc5d0 \\ub098\\uc640 \\uac00\\uc8fc\\uace0 \\uc6b0\\ub9ac \\ubcf4\\uc774 \\uc904\\ub77c\\uaf2c \\uce74\\ub294 \\uadf8\\uac70\\ub294 \\uc778\\uae30 \\uac00\\uc218\\ub4e4\\uc774\\uace0 \\uac70\\uc758 \\ubb34\\uba85 \\uac00\\uc218\\ub4e4\\uc774 \\uadf8\\ub9cc\\ud07c \\ub9ce\\uc740 \\uac00 \\ubd10 \\uadf8\\ub798\\uc11c \\ub098\\ub294 \\uc544 \\ub0b4\\uac00 \\uc778\\uc790 \\uc5ec\\uae30\\uc5d0 \\ub108\\ubb34 \\ube60\\uc838 \\uac16\\uace0 \\ud558 \\uc73c \\ud55c \\uc0ac\\ub78c\\uc744 \\ub108\\ubb34 \\ube60\\uc838 \\uac16\\uace0 \\ubd10\\uc11c\\ub294 \\uc548 \\ub418\\uaca0\\ub2e4 \\uc774\\ub798 \\uc2f6\\uc740 \\uac8c \\ub098\\uc911\\uc5d0 \\uadf8\\ub54c\\ub294 \\uad1c\\ucc2e\\uc558\\ub294\\ub370 \\uc9c0\\ub098\\uace0\\ub294 \\ubb50 \\uc774\\ub798 \\uc54c\\uace0 \\ubcf4\\ub2c8\\uae4c \\uc0ac\\ub78c\\ud55c\\ud14c \\ud658\\uba78\\uc744 \\ucabc\\ub054 \\ub290\\ub07c\\ub4dc\\ub77c\\uad6c \\uadf8\\ub798\\uc11c \\uc5b4 \\uac00\\uc694 \\uadf8 \\ud504\\ub85c \\uadf8\\uac70\\uc5d0 \\ub300\\ud574 \\uac16\\uace0 \\ub108\\ubb34 \\ub0b4\\uac00 \\uc548 \\ube60\\uc838\\ub4e4\\uae30\\ub85c \\uaf2c \\ub9c8\\uc74c \\uba39\\uc5c8\\uc2b5\\ub2c8\\ub2e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b33b0b4f-dbb6-49e5-8835-71d0df883c54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>speaker_1</th>\n",
              "      <th>speaker_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>113814</th>\n",
              "      <td>DKSR20007343</td>\n",
              "      <td>요즘에 트로트가 진짜 많이 이렇게 대세잖아요 방송 막 틀어보면 뭐 방송 상사 뭐 삼...</td>\n",
              "      <td>아 내가 임영웅을 알았는 거는 미스터 트롯 그 프로를 보면서 알았는데 야가 이 사람...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113815</th>\n",
              "      <td>DKSR20007343</td>\n",
              "      <td>별로 저는 그거 노래 그렇게 막 잘하 아 잘하는 건 알겠는데 근데 막 계속 보고 싶...</td>\n",
              "      <td>내가 그 당시에는 임영웅 영웅이한테 빠져 갖고 다른 사람이 안 보여 가주고 몰랐는데...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113816</th>\n",
              "      <td>DKSR20007343</td>\n",
              "      <td>근데 나는 엄마가 그렇게 누군가를 좋아하고 관심있게 보고 뭐 이러는 게 진짜 조금 ...</td>\n",
              "      <td>배우 중에는 내가 영화고 드라마고 이런 거를 잘 안 보기 때문에 나는 좋아하는 사람...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113817</th>\n",
              "      <td>DKSR20007343</td>\n",
              "      <td>나는 요즘에는 유아인 예전에 그 사도나 배테랑 그때 이천십오 년도에 개봉했을 때 그...</td>\n",
              "      <td>개그맨은 옛날에는 우리가 그거 저기 개그 프로 근데 뭐 제목은 내가 모르겠는데 뭐 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113818</th>\n",
              "      <td>DKSR20007343</td>\n",
              "      <td>엄마는 그러면 놀면 어때라는 그 아니 아 맞지 놀면 어때 맞지 유 유재석이 나오는 ...</td>\n",
              "      <td>아 나는 유재석이라카는 그 사람 이미지가 매 이래 찬카 착한 걸로 이르케 보여주고 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b33b0b4f-dbb6-49e5-8835-71d0df883c54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b33b0b4f-dbb6-49e5-8835-71d0df883c54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b33b0b4f-dbb6-49e5-8835-71d0df883c54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b61fedc-7b75-4290-a2cd-47341e903159\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b61fedc-7b75-4290-a2cd-47341e903159')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b61fedc-7b75-4290-a2cd-47341e903159 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  id                                          speaker_1  \\\n",
              "113814  DKSR20007343  요즘에 트로트가 진짜 많이 이렇게 대세잖아요 방송 막 틀어보면 뭐 방송 상사 뭐 삼...   \n",
              "113815  DKSR20007343  별로 저는 그거 노래 그렇게 막 잘하 아 잘하는 건 알겠는데 근데 막 계속 보고 싶...   \n",
              "113816  DKSR20007343  근데 나는 엄마가 그렇게 누군가를 좋아하고 관심있게 보고 뭐 이러는 게 진짜 조금 ...   \n",
              "113817  DKSR20007343  나는 요즘에는 유아인 예전에 그 사도나 배테랑 그때 이천십오 년도에 개봉했을 때 그...   \n",
              "113818  DKSR20007343  엄마는 그러면 놀면 어때라는 그 아니 아 맞지 놀면 어때 맞지 유 유재석이 나오는 ...   \n",
              "\n",
              "                                                speaker_2  \n",
              "113814  아 내가 임영웅을 알았는 거는 미스터 트롯 그 프로를 보면서 알았는데 야가 이 사람...  \n",
              "113815  내가 그 당시에는 임영웅 영웅이한테 빠져 갖고 다른 사람이 안 보여 가주고 몰랐는데...  \n",
              "113816  배우 중에는 내가 영화고 드라마고 이런 거를 잘 안 보기 때문에 나는 좋아하는 사람...  \n",
              "113817  개그맨은 옛날에는 우리가 그거 저기 개그 프로 근데 뭐 제목은 내가 모르겠는데 뭐 ...  \n",
              "113818  아 나는 유재석이라카는 그 사람 이미지가 매 이래 찬카 착한 걸로 이르케 보여주고 ...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCM3CDwsczZK",
        "outputId": "f8d9e859-5431-4228-ee78-ea87cd36e6a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 94448 entries, 0 to 113818\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         94448 non-null  object\n",
            " 1   speaker_1  94448 non-null  object\n",
            " 2   speaker_2  94448 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SalQ-nJW0QRS"
      },
      "outputs": [],
      "source": [
        "# train / test data split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=1097)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqYkNXJKwpoS"
      },
      "outputs": [],
      "source": [
        "# 형태소 분석기 테스트\n",
        "\n",
        "# 4개 분석기 모두 토크나이저 진행 후 결과 가장 좋은 토크나이저 차용 예정\n",
        "\n",
        "test_sentence_1 = \"잘 디디보이소 가가 발 달린 거 아니믄 여 있을낍니더~\"\n",
        "test_sentence_2 = \"여따 놔두이 모르지 찾았어예 담부터 정리 똑띠 하입시더~\"\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()\n",
        "kiwi = Kiwi()\n",
        "komoran = Komoran()\n",
        "hannanum = Hannanum()\n",
        "# mecab = Mecab()\n",
        "\n",
        "print(\"OKT\")\n",
        "print(okt.morphs(test_sentence_1))\n",
        "print(okt.morphs(test_sentence_2))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"kkma\")\n",
        "print(kkma.morphs(test_sentence_1))\n",
        "print(kkma.morphs(test_sentence_2))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Komoran\")\n",
        "print(komoran.morphs(test_sentence_1))\n",
        "print(komoran.morphs(test_sentence_2))\n",
        "print(\"\\n\")\n",
        "\n",
        "# print(\"mecab\")\n",
        "# print(mecab.morphs(test_sentence_1))\n",
        "# print(mecab.morphs(test_sentence_2))\n",
        "# print(\"\\n\")\n",
        "\n",
        "print(\"kiwi\")\n",
        "result = kiwi.analyze(test_sentence_1)\n",
        "kiwi_result_1 = []\n",
        "\n",
        "for sentence in result:\n",
        "  for word in sentence[0]:\n",
        "    kiwi_result_1.append(word.form)\n",
        "\n",
        "\n",
        "result = kiwi.analyze(test_sentence_2)\n",
        "kiwi_result_2 = []\n",
        "\n",
        "for sentence in result:\n",
        "  for word in sentence[0]:\n",
        "    kiwi_result_2.append(word.form)\n",
        "\n",
        "print(kiwi_result_1)\n",
        "print(kiwi_result_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8a7SVwL-bFS"
      },
      "outputs": [],
      "source": [
        "# 형태소 분석기 적용시 토큰의 수가 (max_len 을 결정하기 위한) 얼마나 되는지 보려했는데 시간이 꽤 걸리네요\n",
        "# note : tokenizer 로 split 이외의 메서드를 사용시 걸리는 시간 문제를 어떻게 해결할 것인가\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# data_2 = data.copy()\n",
        "\n",
        "# data_2[\"speaker_1\"] = data_2[\"speaker_1\"].apply(lambda x : tokenizer_kkma(x))\n",
        "# data_2[\"speaker_2\"] = data_2[\"speaker_2\"].apply(lambda x : tokenizer_kkma(x))\n",
        "\n",
        "# # speaker_1과 speaker_2의 리스트 길이 계산\n",
        "# data_2[\"speaker_1_length\"] = data_2[\"speaker_1\"].apply(len)\n",
        "# data_2[\"speaker_2_length\"] = data_2[\"speaker_2\"].apply(len)\n",
        "\n",
        "# # 리스트 길이 분포 시각화\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# plt.hist(data_2[\"speaker_1_length\"], bins=10, alpha=0.5, label='Speaker 1 Lengths')\n",
        "# plt.hist(data_2[\"speaker_2_length\"], bins=10, alpha=0.5, label='Speaker 2 Lengths')\n",
        "\n",
        "# plt.xlabel('List Length')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.title('Distribution of List Lengths in speaker_1 and speaker_2 Columns')\n",
        "# plt.legend(loc='upper right')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6zJgdc2H4hb"
      },
      "outputs": [],
      "source": [
        "# 위 코드라인의 주석 처리와 같은 맥락\n",
        "\n",
        "# speaker_1_lengths = list(data_2[\"speaker_1_length\"])\n",
        "# speaker_2_lengths = list(data_2[\"speaker_2_length\"])\n",
        "\n",
        "# quartiles_1 = np.percentile(speaker_1_lengths, [25, 50, 75])\n",
        "# quartiles_2 = np.percentile(speaker_2_lengths, [25, 50, 75])\n",
        "\n",
        "# print(quartiles_1)\n",
        "# print(quartiles_2)\n",
        "\n",
        "# print(np.mean(quartiles_1))\n",
        "# print(np.mean(quartiles_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYqOaOY9ZQ-b"
      },
      "outputs": [],
      "source": [
        "# kiwi / okt / kkma / komoran / split (띄워쓰기)\n",
        "# 총 5가지 종류의 tokenizer 를 만들어 테스트 진행\n",
        "\n",
        "def tokenizer_kiwi(text):\n",
        "  result = kiwi.analyze(text)\n",
        "  kiwi_result = []\n",
        "\n",
        "  for sentence in result:\n",
        "    for word in sentence[0]:\n",
        "      kiwi_result.append(word.form)\n",
        "\n",
        "  return kiwi_result\n",
        "\n",
        "def tokenizer_okt(text):\n",
        "  return okt.morphs(text)\n",
        "\n",
        "def tokenizer_kkma(text):\n",
        "  return kkma.morphs(text)\n",
        "\n",
        "def tokenizer_komoran(text):\n",
        "  return komoran.morphs(text)\n",
        "\n",
        "def tokenizer_split(text):\n",
        "  return text.split(\" \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxhqz8irxQj4"
      },
      "outputs": [],
      "source": [
        "# vocab (단어와 index 를 매핑해주는 사전) 생성 메서드\n",
        "def build_vocab(dataframe, target_column, tokenizer, min_freq):\n",
        "  tokenized_texts = []\n",
        "\n",
        "  for idx, row in dataframe.iterrows():\n",
        "    tokens = tokenizer(row[target_column])\n",
        "    tokenized_texts.append(tokens)\n",
        "\n",
        "  # counter = Counter(token for tokens in tokenized_texts for token in tokens)\n",
        "  def yield_tokens():\n",
        "    for tokens in tokenized_texts:\n",
        "      yield tokens\n",
        "\n",
        "  vocab = build_vocab_from_iterator(yield_tokens(), specials=['<unk>', '<pad>', '<sos>', '<eos>'], min_freq=min_freq)\n",
        "  # unk 토큰 설정\n",
        "  vocab.set_default_index(vocab['<unk>'])\n",
        "  # vocab = Vocab(counter, specials=['<unk>', '<pad>', '<sos>', '<eos>'], min_freq=min_freq)\n",
        "  return vocab\n",
        "\n",
        "# # torch 의 길이를 맞춰주는 메서드\n",
        "# def collate_fn(batch, pad_token='<pad>', max_len=30):\n",
        "#     src_batch, trg_batch = zip(*batch)\n",
        "\n",
        "#     # 패딩 값 설정\n",
        "#     pad_idx_src = vocab_src[pad_token]\n",
        "#     pad_idx_trg = vocab_trg[pad_token]\n",
        "\n",
        "#     # 패딩 및 텐서 변환\n",
        "#     src_batch = [torch.cat([sample, torch.full((max_len - len(sample),), pad_idx_src)]) if len(sample) < max_len else sample[:max_len] for sample in src_batch]\n",
        "#     trg_batch = [torch.cat([sample, torch.full((max_len - len(sample),), pad_idx_trg)]) if len(sample) < max_len else sample[:max_len] for sample in trg_batch]\n",
        "\n",
        "#     # 배치 텐서 생성\n",
        "#     src_batch = torch.stack(src_batch)\n",
        "#     trg_batch = torch.stack(trg_batch)\n",
        "\n",
        "#     return src_batch, trg_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CrmS-CXZWee"
      },
      "outputs": [],
      "source": [
        "# torch 의 dataset / dataloader\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, vocab_src, vocab_trg, max_len=30):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab_src = vocab_src\n",
        "        self.vocab_trg = vocab_trg\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.data.iloc[idx, 1]\n",
        "        trg_text = self.data.iloc[idx, 2]\n",
        "        src_tokens = self.tokenizer(src_text)\n",
        "        trg_tokens = self.tokenizer(trg_text)\n",
        "\n",
        "        # <sos>, <eos> 토큰 추가, max_len을 고려하여 자르기\n",
        "        src_indexes = [self.vocab_src['<sos>']] + [self.vocab_src[token] for token in src_tokens][:self.max_len-2] + [self.vocab_src['<eos>']]\n",
        "        trg_indexes = [self.vocab_trg['<sos>']] + [self.vocab_trg[token] for token in trg_tokens][:self.max_len-2] + [self.vocab_trg['<eos>']]\n",
        "\n",
        "        if len(src_indexes) < self.max_len:\n",
        "            src_indexes += [self.vocab_src['<pad>']] * (self.max_len - len(src_indexes))\n",
        "        if len(trg_indexes) < self.max_len:\n",
        "            trg_indexes += [self.vocab_trg['<pad>']] * (self.max_len - len(trg_indexes))\n",
        "\n",
        "        return torch.tensor(src_indexes), torch.tensor(trg_indexes)\n",
        "\n",
        "\n",
        "vocab_src = build_vocab(train, \"speaker_1\", tokenizer_split, min_freq=1)\n",
        "vocab_trg = build_vocab(train, \"speaker_2\", tokenizer_split, min_freq=1)\n",
        "\n",
        "# Dataset 및 DataLoader\n",
        "train_dataset = CustomTextDataset(train, tokenizer_split, vocab_src, vocab_trg)\n",
        "test_dataset = CustomTextDataset(test, tokenizer_split, vocab_src, vocab_trg)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# collate_fn 이 max_len torch 길이를 맞춰주기 위한 역할인데,\n",
        "# 여기서 두 가지 아이디어가 존재한다.\n",
        "#   1. 단순 길이 기준으로 자르기\n",
        "#   2. vocab 의 우선도 기준으로 자르기\n",
        "# 만약 단순히 토큰의 최대 길이에 맞춰 padding 을 넣어주면 쓸데없이 크기만 커지는 걸 방지하기 위함\n",
        "\n",
        "# 가변 배치 학습\n",
        "# sampler 를 이용하면 되는데 이 부분은 우선 pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbOW0mzKgiHL",
        "outputId": "8cdce0a2-ea00-4c38-d3cb-f2394db6bea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "375654\n",
            "387764\n"
          ]
        }
      ],
      "source": [
        "print(len(vocab_src))\n",
        "print(len(vocab_trg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaFQmMANCsR9",
        "outputId": "d659861c-b43d-4277-f649-6effae081268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1:\n",
            "Source Batch:\n",
            "tensor([[     2,    102,    387,  ...,      1,      1,      1],\n",
            "        [     2,    404,  95229,  ...,      1,      1,      1],\n",
            "        [     2,     16,     34,  ...,      1,      1,      1],\n",
            "        ...,\n",
            "        [     2,    191,  63895,  ..., 131141,     53,      3],\n",
            "        [     2,  34335,     10,  ...,      1,      1,      1],\n",
            "        [     2,   1236,    611,  ...,      1,      1,      1]])\n",
            "Target Batch:\n",
            "tensor([[   2, 1768,  244,  ..., 5164,   65,    3],\n",
            "        [   2,   16, 1935,  ...,    1,    1,    1],\n",
            "        [   2,   25,   16,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,   55,  193,  ...,    1,    1,    1],\n",
            "        [   2,   70,   95,  ...,   13, 4532,    3],\n",
            "        [   2,  470,   30,  ...,   66,  138,    3]])\n",
            "\n",
            "\n",
            "Batch 2:\n",
            "Source Batch:\n",
            "tensor([[     2,    213,     85,  ...,      1,      1,      1],\n",
            "        [     2,    430, 122208,  ...,      1,      1,      1],\n",
            "        [     2,     19, 134856,  ...,    105,    186,      3],\n",
            "        ...,\n",
            "        [     2,    430,     70,  ...,   1030,   3027,      3],\n",
            "        [     2,     95,     70,  ...,      1,      1,      1],\n",
            "        [     2,   3059,     42,  ...,      1,      1,      1]])\n",
            "Target Batch:\n",
            "tensor([[    2,   494,   435,  ...,     1,     1,     1],\n",
            "        [    2,   885, 12803,  ...,     1,     1,     1],\n",
            "        [    2,   339,  8732,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    2, 45465, 35278,  ...,    43,    15,     3],\n",
            "        [    2,   124, 91741,  ...,     1,     1,     1],\n",
            "        [    2,   106,   817,  ...,     1,     1,     1]])\n",
            "\n",
            "\n",
            "Batch 3:\n",
            "Source Batch:\n",
            "tensor([[    2,   464,   399,  ...,     4,   419,     3],\n",
            "        [    2,    12,    34,  ...,    45,    14,     3],\n",
            "        [    2, 77045,    19,  ..., 86394, 35272,     3],\n",
            "        ...,\n",
            "        [    2,   122,    32,  ..., 28569,   156,     3],\n",
            "        [    2,   376,    20,  ...,     1,     1,     1],\n",
            "        [    2,   151, 16979,  ...,     1,     1,     1]])\n",
            "Target Batch:\n",
            "tensor([[     2,  32577,    107,  ...,      1,      1,      1],\n",
            "        [     2,  66510,    104,  ...,   5351, 171016,      3],\n",
            "        [     2,  61927,   2621,  ...,      1,      1,      1],\n",
            "        ...,\n",
            "        [     2,     25,  47893,  ...,     31,     19,      3],\n",
            "        [     2,   1854,      9,  ...,      7, 145845,      3],\n",
            "        [     2,   1445,   3450,  ...,   7744,    150,      3]])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataLoader 예시 확인\n",
        "for i, (src_batch, trg_batch) in enumerate(train_loader):\n",
        "    print(f\"Batch {i+1}:\")\n",
        "    print(f\"Source Batch:\\n{src_batch}\")\n",
        "    print(f\"Target Batch:\\n{trg_batch}\")\n",
        "    print(\"\\n\")\n",
        "    if i == 2:  # 3개의 배치만 출력\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPQYo58qZEwJ",
        "outputId": "a7489b50-45b0-4017-bd88-10d73d7a0ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 2 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 3 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 4 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 5 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 6 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 7 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 8 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 9 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 10 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 11 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 12 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 13 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 14 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 15 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 16 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 17 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 18 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 19 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 20 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 21 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 22 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 23 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 24 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 25 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 26 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 27 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 28 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 29 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 30 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 31 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 32 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 33 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 34 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 35 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 36 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 37 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 38 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 39 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 40 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 41 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 42 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 43 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 44 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 45 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 46 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 47 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 48 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 49 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 50 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 51 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 52 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 53 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 54 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 55 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 56 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 57 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 58 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 59 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 60 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 61 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 62 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 63 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 64 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 65 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 66 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 67 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 68 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 69 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 70 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 71 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 72 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 73 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 74 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 75 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 76 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 77 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 78 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 79 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 80 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 81 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 82 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 83 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 84 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 85 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 86 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 87 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 88 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 89 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 90 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 91 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 92 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 93 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 94 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 95 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 96 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 97 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 98 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 99 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 100 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 101 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 102 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 103 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 104 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 105 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 106 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 107 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 108 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 109 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 110 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 111 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 112 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 113 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 114 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 115 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 116 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 117 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 118 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 119 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 120 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 121 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 122 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 123 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 124 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 125 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 126 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 127 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 128 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 129 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 130 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 131 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 132 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 133 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 134 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 135 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 136 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 137 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 138 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 139 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 140 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 141 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 142 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 143 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 144 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 145 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 146 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 147 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 148 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 149 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 150 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 151 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 152 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 153 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 154 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 155 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 156 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 157 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 158 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 159 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 160 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 161 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 162 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 163 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 164 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 165 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 166 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 167 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 168 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 169 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 170 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 171 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 172 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 173 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 174 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 175 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 176 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 177 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 178 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 179 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 180 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 181 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 182 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 183 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 184 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 185 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 186 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 187 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 188 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 189 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 190 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 191 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 192 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 193 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 194 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 195 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 196 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 197 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 198 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 199 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 200 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 201 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 202 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 203 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 204 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 205 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 206 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 207 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 208 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 209 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 210 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 211 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 212 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 213 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 214 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 215 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 216 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 217 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 218 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 219 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 220 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 221 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 222 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 223 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 224 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 225 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 226 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 227 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 228 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 229 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 230 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 231 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 232 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 233 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 234 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 235 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 236 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 237 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 238 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 239 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 240 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 241 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 242 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 243 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 244 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 245 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 246 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 247 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 248 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 249 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 250 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 251 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 252 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 253 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 254 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 255 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 256 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 257 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 258 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 259 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 260 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 261 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 262 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 263 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 264 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 265 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 266 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 267 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 268 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 269 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 270 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 271 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 272 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 273 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 274 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 275 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 276 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 277 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 278 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 279 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 280 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 281 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 282 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 283 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 284 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 285 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 286 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 287 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 288 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 289 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 290 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 291 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 292 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 293 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 294 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 295 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 296 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 297 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 298 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 299 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 300 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 301 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 302 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 303 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 304 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 305 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 306 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 307 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 308 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 309 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 310 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 311 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 312 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 313 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 314 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 315 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 316 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 317 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 318 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 319 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 320 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 321 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 322 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 323 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 324 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 325 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 326 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 327 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 328 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 329 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 330 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 331 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 332 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 333 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 334 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 335 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 336 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 337 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 338 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 339 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 340 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 341 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 342 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 343 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 344 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 345 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 346 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 347 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 348 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 349 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 350 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 351 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 352 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 353 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 354 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 355 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 356 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 357 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 358 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 359 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 360 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 361 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 362 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 363 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 364 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 365 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 366 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 367 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 368 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 369 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 370 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 371 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 372 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 373 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 374 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 375 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 376 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 377 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 378 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 379 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 380 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 381 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 382 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 383 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 384 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 385 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 386 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 387 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 388 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 389 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 390 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 391 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 392 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 393 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 394 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 395 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 396 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 397 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 398 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 399 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 400 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 401 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 402 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 403 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 404 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 405 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 406 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 407 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 408 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 409 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 410 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 411 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 412 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 413 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 414 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 415 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 416 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 417 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 418 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 419 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 420 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 421 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 422 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 423 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 424 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 425 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 426 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 427 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 428 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 429 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 430 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 431 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 432 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 433 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 434 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 435 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 436 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 437 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 438 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 439 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 440 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 441 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 442 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 443 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 444 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 445 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 446 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 447 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 448 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 449 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 450 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 451 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 452 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 453 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 454 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 455 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 456 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 457 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 458 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 459 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 460 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 461 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 462 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 463 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 464 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 465 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 466 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 467 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 468 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 469 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 470 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 471 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 472 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 473 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 474 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 475 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 476 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 477 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 478 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 479 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 480 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 481 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 482 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 483 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 484 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 485 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 486 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 487 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 488 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 489 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 490 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 491 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 492 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 493 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 494 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 495 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 496 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 497 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 498 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 499 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 500 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 501 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 502 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 503 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 504 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 505 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 506 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 507 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 508 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 509 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 510 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 511 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 512 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 513 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 514 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 515 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 516 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 517 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 518 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 519 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 520 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 521 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 522 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 523 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 524 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 525 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 526 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 527 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 528 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 529 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 530 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 531 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 532 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 533 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 534 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 535 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 536 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 537 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 538 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 539 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 540 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 541 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 542 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 543 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 544 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 545 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 546 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 547 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 548 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 549 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 550 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 551 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 552 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 553 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 554 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 555 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 556 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 557 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 558 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 559 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 560 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 561 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 562 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 563 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 564 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 565 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 566 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 567 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 568 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 569 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 570 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 571 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 572 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 573 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 574 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 575 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 576 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 577 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 578 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 579 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 580 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 581 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 582 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 583 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 584 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 585 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 586 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 587 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 588 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 589 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 590 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 591 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 592 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 593 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 594 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 595 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 596 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 597 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 598 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 599 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 600 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 601 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 602 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 603 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 604 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 605 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 606 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 607 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 608 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 609 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 610 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 611 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 612 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 613 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 614 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 615 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 616 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 617 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 618 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 619 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 620 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 621 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 622 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 623 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 624 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 625 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 626 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 627 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 628 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 629 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 630 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 631 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 632 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 633 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 634 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 635 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 636 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 637 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 638 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 639 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 640 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 641 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 642 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 643 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 644 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 645 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 646 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 647 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 648 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 649 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 650 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 651 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 652 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 653 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 654 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 655 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 656 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 657 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 658 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 659 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 660 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 661 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 662 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 663 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 664 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 665 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 666 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 667 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 668 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 669 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 670 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 671 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 672 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 673 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 674 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 675 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 676 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 677 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 678 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 679 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 680 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 681 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 682 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 683 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 684 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 685 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 686 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 687 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 688 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 689 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 690 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 691 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 692 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 693 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 694 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 695 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 696 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 697 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 698 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 699 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 700 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 701 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 702 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 703 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 704 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 705 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 706 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 707 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 708 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 709 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 710 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 711 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 712 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 713 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 714 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 715 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 716 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 717 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 718 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 719 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 720 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 721 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 722 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 723 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 724 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 725 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 726 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 727 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 728 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 729 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 730 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 731 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 732 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 733 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 734 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 735 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 736 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 737 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 738 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 739 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 740 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 741 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 742 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 743 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 744 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 745 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 746 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 747 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 748 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 749 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 750 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 751 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 752 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 753 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 754 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 755 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 756 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 757 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 758 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 759 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 760 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 761 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 762 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 763 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 764 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 765 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 766 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 767 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 768 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 769 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 770 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 771 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 772 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 773 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 774 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 775 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 776 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 777 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 778 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 779 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 780 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 781 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 782 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 783 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 784 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 785 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 786 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 787 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 788 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 789 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 790 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 791 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 792 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 793 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 794 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 795 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 796 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 797 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 798 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 799 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 800 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 801 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 802 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 803 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 804 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 805 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 806 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 807 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 808 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 809 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 810 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 811 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 812 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 813 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 814 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 815 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 816 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 817 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 818 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 819 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 820 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 821 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 822 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 823 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 824 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 825 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 826 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 827 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 828 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 829 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 830 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 831 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 832 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 833 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 834 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 835 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 836 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 837 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 838 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 839 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 840 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 841 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 842 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 843 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 844 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 845 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 846 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 847 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 848 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 849 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 850 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 851 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 852 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 853 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 854 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 855 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 856 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 857 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 858 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 859 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 860 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 861 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 862 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 863 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 864 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 865 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 866 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 867 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 868 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 869 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 870 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 871 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 872 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 873 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 874 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 875 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 876 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 877 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 878 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 879 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 880 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 881 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 882 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 883 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 884 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 885 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 886 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 887 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 888 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 889 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 890 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 891 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 892 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 893 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 894 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 895 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 896 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 897 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 898 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 899 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 900 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 901 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 902 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 903 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 904 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 905 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 906 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 907 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 908 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 909 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 910 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 911 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 912 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 913 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 914 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 915 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 916 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 917 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 918 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 919 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 920 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 921 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 922 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 923 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 924 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 925 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 926 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 927 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 928 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 929 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 930 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 931 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 932 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 933 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 934 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 935 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 936 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 937 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 938 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 939 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 940 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 941 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 942 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 943 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 944 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 945 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 946 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 947 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 948 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 949 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 950 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 951 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 952 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 953 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 954 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 955 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 956 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 957 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 958 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 959 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 960 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 961 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 962 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 963 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 964 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 965 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 966 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 967 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 968 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 969 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 970 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 971 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 972 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 973 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 974 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 975 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 976 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 977 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 978 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 979 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 980 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 981 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 982 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 983 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 984 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 985 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 986 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 987 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 988 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 989 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 990 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 991 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 992 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 993 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 994 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 995 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 996 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 997 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 998 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 999 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1000 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1001 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1002 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1003 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1004 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1005 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1006 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1007 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1008 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1009 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1010 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1011 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1012 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1013 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1014 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1015 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1016 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1017 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1018 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1019 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1020 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1021 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1022 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1023 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1024 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1025 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1026 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1027 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1028 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1029 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1030 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1031 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1032 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1033 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1034 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1035 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1036 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1037 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1038 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1039 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1040 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1041 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1042 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1043 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1044 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1045 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1046 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1047 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1048 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1049 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1050 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1051 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1052 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1053 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1054 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1055 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1056 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1057 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1058 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1059 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1060 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1061 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1062 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1063 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1064 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1065 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1066 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1067 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1068 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1069 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1070 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1071 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1072 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1073 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1074 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1075 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1076 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1077 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1078 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1079 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1080 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1081 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1082 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1083 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1084 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1085 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1086 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1087 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1088 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1089 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1090 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1091 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1092 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1093 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1094 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1095 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1096 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1097 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1098 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1099 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1100 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1101 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1102 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1103 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1104 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1105 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1106 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1107 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1108 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1109 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1110 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1111 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1112 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1113 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1114 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1115 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1116 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1117 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1118 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1119 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1120 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1121 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1122 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1123 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1124 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1125 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1126 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1127 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1128 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1129 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1130 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1131 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1132 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1133 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1134 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1135 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1136 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1137 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1138 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1139 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1140 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1141 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1142 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1143 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1144 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1145 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1146 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1147 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1148 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1149 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1150 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1151 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1152 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1153 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1154 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1155 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1156 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1157 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1158 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1159 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1160 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1161 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1162 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1163 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1164 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1165 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1166 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1167 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1168 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1169 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1170 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1171 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1172 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1173 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1174 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1175 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1176 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1177 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1178 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1179 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1180 - Source Shape: torch.Size([64, 30]), Target Shape: torch.Size([64, 30])\n",
            "Batch 1181 - Source Shape: torch.Size([38, 30]), Target Shape: torch.Size([38, 30])\n"
          ]
        }
      ],
      "source": [
        "# 학습 속도나 런타임 보고 배치 크기 변경 예정\n",
        "\n",
        "for i, (src_batch, trg_batch) in enumerate(train_loader):\n",
        "    print(f\"Batch {i+1} - Source Shape: {src_batch.shape}, Target Shape: {trg_batch.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W1tpvvbrE2L",
        "outputId": "09d60f6f-2000-47e6-cf40-7d11caea2dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAmykvuTEb0O"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
        "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
        "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # query: [batch_size, query_len, hidden_dim]\n",
        "        # key: [batch_size, key_len, hidden_dim]\n",
        "        # value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Q: [batch_size, query_len, hidden_dim]\n",
        "        # K: [batch_size, key_len, hidden_dim]\n",
        "        # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "        # K: [batch_size, n_heads, key_len, head_dim]\n",
        "        # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "        # Attention Energy 계산\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 마스크(mask)를 사용하는 경우\n",
        "        if mask is not None:\n",
        "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIW6omqhHLt4"
      },
      "outputs": [],
      "source": [
        "# 포워드 레이어 (선형변환)\n",
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzEqBfRQHikJ"
      },
      "outputs": [],
      "source": [
        "# 인코더 레이어\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # DH : forward 메서드를 호출할 필요가 없음\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66X3agw8HlqB"
      },
      "outputs": [],
      "source": [
        "# 인코더 모델 생성\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        # nn.Embedding : https://wikidocs.net/64779\n",
        "        # 임베딩은 결국 룩업 테이블을 생성하는 것...!\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        # nn.ModuleList : nn.Module 클래스를 확장하는 데에 사용하는 유틸리티\n",
        "        # 여러 층으로 구성되어있는 Encoder 부분을 관리하기 쉽도록 활용함\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        # positional encoding\n",
        "\n",
        "        # pos: [batch_size, src_len]\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # note : 으음 이게 잘 되나?\n",
        "        # 위치 정보가 충분히 반영되지 않을 것 같은 느낌.\n",
        "        # nn.Emdedding 의 임베딩 테이블은 랜덤한 숫자들로 생성될텐데,,,\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src # 마지막 레이어의 출력을 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzmCYzVMHmGe"
      },
      "outputs": [],
      "source": [
        "# 디코더 레이어\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 자기 자신에 대하여 어텐션(attention)\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4otbvR-Hn_3"
      },
      "outputs": [],
      "source": [
        "# 디코더 모델 생성\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W09xyUI7Hq0C"
      },
      "outputs": [],
      "source": [
        "# 트랜스포머 모델\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PMTUjQsHsaX"
      },
      "outputs": [],
      "source": [
        "# 모델 튜닝\n",
        "\n",
        "INPUT_DIM = len(vocab_src)\n",
        "OUTPUT_DIM = len(vocab_trg)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al7u601IHuju"
      },
      "outputs": [],
      "source": [
        "# SRC_PAD_IDX = vocab_src.get_stoi[vocab_src.pad_token]\n",
        "# TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "SRC_PAD_IDX = vocab_src[\"<pad>\"]\n",
        "TRG_PAD_IDX = vocab_trg[\"<pad>\"]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pky3vvLSIYmz",
        "outputId": "d5a24e05-40ce-4723-fef8-a5b622b2a952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 299,095,220 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# 파라미터 개수\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTuMxHPdI1en",
        "outputId": "c31e129c-a61f-4fcc-e3e0-3e4fae2befd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(375654, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(387764, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=387764, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5AEcu8SI3RE"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6da6lBZI4xf"
      },
      "outputs": [],
      "source": [
        "# 모델 학습(train) 함수\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch[0].to(device)\n",
        "        trg = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "\n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdAQDeNZI6Kj"
      },
      "outputs": [],
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0]\n",
        "            trg = batch[1]\n",
        "\n",
        "            # 출력 단어의 마지F막 인덱스(<eos>)는 제외\n",
        "            # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            # output: [배치 크기, trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기, trg_len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge20aQEWI7iN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBqOZFGBI9R2",
        "outputId": "cd9b22e0-b89d-4b85-99f9-284d426a49ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 7m 7s\n",
            "\tTrain Loss: 8.042 | Train PPL: 3109.231\n",
            "Epoch: 02 | Time: 7m 7s\n",
            "\tTrain Loss: 6.981 | Train PPL: 1076.395\n",
            "Epoch: 03 | Time: 7m 8s\n",
            "\tTrain Loss: 6.219 | Train PPL: 502.388\n",
            "Epoch: 04 | Time: 7m 8s\n",
            "\tTrain Loss: 5.385 | Train PPL: 218.063\n",
            "Epoch: 05 | Time: 7m 8s\n",
            "\tTrain Loss: 4.520 | Train PPL: 91.813\n",
            "Epoch: 06 | Time: 7m 9s\n",
            "\tTrain Loss: 3.752 | Train PPL: 42.617\n",
            "Epoch: 07 | Time: 7m 9s\n",
            "\tTrain Loss: 3.179 | Train PPL: 24.015\n",
            "Epoch: 08 | Time: 7m 9s\n",
            "\tTrain Loss: 2.796 | Train PPL: 16.372\n",
            "Epoch: 09 | Time: 7m 9s\n",
            "\tTrain Loss: 2.531 | Train PPL: 12.562\n",
            "Epoch: 10 | Time: 7m 9s\n",
            "\tTrain Loss: 2.329 | Train PPL: 10.266\n",
            "Epoch: 11 | Time: 7m 9s\n",
            "\tTrain Loss: 2.168 | Train PPL: 8.740\n",
            "Epoch: 12 | Time: 7m 9s\n",
            "\tTrain Loss: 2.038 | Train PPL: 7.679\n",
            "Epoch: 13 | Time: 7m 9s\n",
            "\tTrain Loss: 1.928 | Train PPL: 6.873\n",
            "Epoch: 14 | Time: 7m 9s\n",
            "\tTrain Loss: 1.836 | Train PPL: 6.274\n",
            "Epoch: 15 | Time: 7m 9s\n",
            "\tTrain Loss: 1.755 | Train PPL: 5.784\n",
            "Epoch: 16 | Time: 7m 9s\n",
            "\tTrain Loss: 1.682 | Train PPL: 5.378\n",
            "Epoch: 17 | Time: 7m 9s\n",
            "\tTrain Loss: 1.618 | Train PPL: 5.043\n",
            "Epoch: 18 | Time: 7m 9s\n",
            "\tTrain Loss: 1.561 | Train PPL: 4.763\n",
            "Epoch: 19 | Time: 7m 9s\n",
            "\tTrain Loss: 1.508 | Train PPL: 4.516\n",
            "Epoch: 20 | Time: 7m 9s\n",
            "\tTrain Loss: 1.459 | Train PPL: 4.302\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC8ICjpSwsIv"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'transformer_model_v1.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQbeAH86f5dn"
      },
      "outputs": [],
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50, logging=True):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    max_len = len(sentence) + 1\n",
        "    if isinstance(sentence, type(str)):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsWqsLxRsvR6"
      },
      "outputs": [],
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50, logging=True):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    max_len = len(sentence) + 1\n",
        "    # if isinstance(sentence, type(str)):\n",
        "    #     # nlp = spacy.load('de_core_news_sm')\n",
        "    #     tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    # else:\n",
        "    #     tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = tokenizer_split(sentence)\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    # src_indexes = [src_field.get_stoi()[token] for token in tokens]\n",
        "    src_indexes = [src_field.get_stoi().get(token, src_field.get_stoi()[\"<unk>\"]) for token in tokens]\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [trg_field[\"<sos>\"]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == trg_field[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [trg_field.get_itos()[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "801cvtYP2b2d"
      },
      "outputs": [],
      "source": [
        "# 변환된 문장 출력\n",
        "\n",
        "example_idx = range(0, 16000)\n",
        "\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "tokens = [sentence.split() for sentence in test_df['dialects']]\n",
        "references = [[sentence.replace(' ?', '?').replace(' .', '.').replace(' ,', ',')]\n",
        "              for sentence in test_df['dialects']][0:16000]\n",
        "predictions = []\n",
        "\n",
        "for example_ind in example_idx:\n",
        "  src = vars(test_data.examples[example_ind])['src']\n",
        "  trg = vars(test_data.examples[example_ind])['trg']\n",
        "\n",
        "# print(f'소스 문장: {src}')\n",
        "# print(f'타겟 문장: {trg}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device, logging=True)\n",
        "  output = []\n",
        "  for i, tok in enumerate(translation) :\n",
        "        if tok == '<unk>' :\n",
        "            output.append(tokens[example_ind][min(i,len(tokens[example_ind])-1)])\n",
        "        else:\n",
        "            output.append(translation[i])\n",
        "  output_sentence = ' '.join(output).replace(' ?', '?').replace(' .', '.').replace(' ,', ',')\n",
        "  predictions.append(output_sentence)\n",
        "\n",
        "\n",
        "  print(\"모델 출력 결과:\", \" \".join(output), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUryf5BqQfNt",
        "outputId": "aea000d8-02ab-46e9-fa8e-40899b0c0d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 소스 토큰: ['<sos>', '오늘', '저녁으로', '뭐먹을까?', '<eos>']\n",
            "소스 문장 인덱스: [2, 523, 17150, 0, 3]\n",
            "대답: ['근데', '그', '하고', '보고', '뭘', '국내', '오히려', '다녔는데', '그', '뭘', '끼니로도', '이렇게', '딱히', '공과금이라']\n",
            "\n",
            "\n",
            "전체 소스 토큰: ['<sos>', '어제', '저녁에는', '뭐', '했어?', '<eos>']\n",
            "소스 문장 인덱스: [2, 1067, 7614, 5, 0, 3]\n",
            "대답: ['때', '근데', '느셔가지고', '이렇게', '무료하니', '<eos>']\n",
            "\n",
            "\n",
            "전체 소스 토큰: ['<sos>', '아침에', '일찍', '일어나는', '건', '피곤한', '일이지?', '<eos>']\n",
            "소스 문장 인덱스: [2, 684, 1158, 2958, 97, 12561, 0, 3]\n",
            "대답: ['때', '근데', '느셔가지고', '이렇게', '무료하니', '<eos>']\n",
            "\n",
            "\n",
            "전체 소스 토큰: ['<sos>', '내일은', '풋살하고', '싶은데', '날씨가', '좋을지', '모르겠어', '<eos>']\n",
            "소스 문장 인덱스: [2, 8749, 53917, 345, 839, 7329, 1378, 3]\n",
            "대답: ['때', '근데', '있는', '사라지니깐', '베드', '했지만', '<eos>']\n",
            "\n",
            "\n",
            "전체 소스 토큰: ['<sos>', '맥북', '신형이', '나왔던데,', '좋아보여?', '<eos>']\n",
            "소스 문장 인덱스: [2, 8766, 71119, 0, 0, 3]\n",
            "대답: ['때', '근데', '그', '그라피', '진짜', '아우', '키로', '거', '같은데', '그리고', '자기', '약간', '찬물로', '보니까', '진짜', '그냥', '좋아하는데', '요즘', '많은']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "translation, attention = translate_sentence(\"오늘 저녁으로 뭐먹을까?\", vocab_src, vocab_src, model, device, logging=True)\n",
        "print(\"대답:\", translation)\n",
        "print(\"\\n\")\n",
        "\n",
        "translation, attention = translate_sentence(\"어제 저녁에는 뭐 했어?\", vocab_src, vocab_src, model, device, logging=True)\n",
        "print(\"대답:\", translation)\n",
        "print(\"\\n\")\n",
        "\n",
        "translation, attention = translate_sentence(\"아침에 일찍 일어나는 건 피곤한 일이지?\", vocab_src, vocab_src, model, device, logging=True)\n",
        "print(\"대답:\", translation)\n",
        "print(\"\\n\")\n",
        "\n",
        "translation, attention = translate_sentence(\"내일은 풋살하고 싶은데 날씨가 좋을지 모르겠어\", vocab_src, vocab_src, model, device, logging=True)\n",
        "print(\"대답:\", translation)\n",
        "print(\"\\n\")\n",
        "\n",
        "translation, attention = translate_sentence(\"맥북 신형이 나왔던데, 좋아보여?\", vocab_src, vocab_src, model, device, logging=True)\n",
        "print(\"대답:\", translation)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuKwy0t73RnN"
      },
      "outputs": [],
      "source": [
        "while(1):\n",
        "    question = input(\"Question: \")\n",
        "    if question == 'quit':\n",
        "        break\n",
        "    max_len = input(\"Maximum Reply Length: \")\n",
        "    enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
        "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
        "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)\n",
        "    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu0nwgeHUJAq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit ('3.10.6')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "a6bbcf36dc5df263ca68502d6771d4ac689cc117f1ed616cc5072a0f313fc5b7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
